{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Webmininglab3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Question: 1**"
      ],
      "metadata": {
        "id": "9wGrUf1Z-rnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCgrR7x5-nBP",
        "outputId": "ad128296-f5a4-4b94-84fd-ee0e825096e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a : {'counter': 2, 'cordinate': [(1, 2), (3, 2)]}\n",
            "and : {'counter': 1, 'cordinate': [(5, 2)]}\n",
            "applications : {'counter': 2, 'cordinate': [(1, 8), (4, 7)]}\n",
            "be : {'counter': 1, 'cordinate': [(4, 3)]}\n",
            "beautiful : {'counter': 1, 'cordinate': [(2, 0)]}\n",
            "can : {'counter': 1, 'cordinate': [(4, 2)]}\n",
            "crawling : {'counter': 1, 'cordinate': [(5, 3)]}\n",
            "for : {'counter': 4, 'cordinate': [(1, 5), (2, 4), (3, 5), (4, 5)]}\n",
            "framework : {'counter': 1, 'cordinate': [(1, 4)]}\n",
            "is : {'counter': 4, 'cordinate': [(1, 1), (2, 2), (3, 1), (5, 5)]}\n",
            "it : {'counter': 1, 'cordinate': [(3, 0)]}\n",
            "java : {'counter': 1, 'cordinate': [(4, 0)]}\n",
            "package : {'counter': 1, 'cordinate': [(3, 4)]}\n",
            "pages : {'counter': 1, 'cordinate': [(3, 8)]}\n",
            "parsing : {'counter': 1, 'cordinate': [(3, 6)]}\n",
            "portable : {'counter': 1, 'cordinate': [(1, 3)]}\n",
            "programming : {'counter': 1, 'cordinate': [(4, 1)]}\n",
            "python : {'counter': 1, 'cordinate': [(3, 3)]}\n",
            "scraping : {'counter': 2, 'cordinate': [(2, 6), (5, 0)]}\n",
            "selenium : {'counter': 1, 'cordinate': [(1, 0)]}\n",
            "soup : {'counter': 1, 'cordinate': [(2, 1)]}\n",
            "testing : {'counter': 1, 'cordinate': [(1, 6)]}\n",
            "the : {'counter': 1, 'cordinate': [(3, 7)]}\n",
            "used : {'counter': 1, 'cordinate': [(4, 4)]}\n",
            "useful : {'counter': 2, 'cordinate': [(2, 3), (5, 6)]}\n",
            "web : {'counter': 5, 'cordinate': [(1, 7), (2, 5), (4, 6), (5, 1), (5, 4)]}\n"
          ]
        }
      ],
      "source": [
        "import re \n",
        "files =['ID1','ID2','ID3','ID4','ID5'] \n",
        "indexer={}\n",
        "for id,doc in enumerate(files): \n",
        "   filenum = doc+\".txt\" \n",
        "   with open(filenum,'r') as fp: \n",
        "    data = \"\".join(fp.readlines()) \n",
        "    data = data.lower() \n",
        "    extractwords = re.findall(r\"([a-z0-9-]+)\",data) \n",
        "    for position,word in enumerate(extractwords): \n",
        "      if word[-1]=='s': \n",
        "        if word[:-1] in indexer: \n",
        "          word = word[:-1] \n",
        "        elif word[:-2] in indexer: \n",
        "          word = word[:-2] \n",
        "\n",
        "      if word not in indexer: \n",
        "        indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "      else: \n",
        "        indexer[word]['counter']+=1 \n",
        "        indexer[word]['cordinate'].append((id+1,position)) \n",
        "from collections import OrderedDict \n",
        "pos = OrderedDict(sorted(indexer.items())) \n",
        "with open(\"inverted.txt\",'w') as fp: \n",
        "  for key in pos: \n",
        "    print(f\"{key} : {pos[key]}\") \n",
        "    fp.write(f\"{key} : {pos[key]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION : 2**\n",
        "pt 1"
      ],
      "metadata": {
        "id": "hH7k-cBAaEcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "textfiles =['ID1','ID2','ID3','ID4','ID5'] \n",
        "indexer={}\n",
        "for id,doc in enumerate(textfiles): \n",
        "   filenum = doc+\".txt\" \n",
        "   with open(filenum,'r') as fp: \n",
        "    data = \"\".join(fp.readlines()) \n",
        "    data = data.lower() \n",
        "    # extractwords = re.findall(r\"([a-z0-9-]+)\",data) \n",
        "    # for position,word in enumerate(extractwords): \n",
        "    #   if word[-1]=='s': \n",
        "    #     if word[:-1] in indexer: \n",
        "    #       word = word[:-1] \n",
        "    #     elif word[:-2] in indexer: \n",
        "    #       word = word[:-2] \n",
        "    if re.findall(r\"\\bselenium\\b\", data) and re.findall(r\"\\bweb\\b\", data):\n",
        "      print(\"Match found in\", filenum)\n",
        "      ext_words1 = re.findall(r\"\\bselenium\\b\", data) \n",
        "      ext_words2 = re.findall(r\"\\bweb\\b\", data) \n",
        "      for pos,word in enumerate(ext_words1):\n",
        "        if word not in indexer: \n",
        "          indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "        else: \n",
        "          indexer[word]['counter']+=1 \n",
        "          indexer[word]['cordinate'].append((id+1,position)) \n",
        "      for pos,word in enumerate(ext_words2):\n",
        "        if word not in indexer: \n",
        "          indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "        else: \n",
        "          indexer[word]['counter']+=1 \n",
        "          indexer[word]['cordinate'].append((id+1,position)) \n",
        "\n",
        "from collections import OrderedDict \n",
        "pos = OrderedDict(sorted(indexer.items())) \n",
        "with open(\"inverted.txt\",'w') as fp: \n",
        "  for key in pos: \n",
        "    print(f\"{key} : {pos[key]}\") \n",
        "    fp.write(f\"{key} : {pos[key]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mslRif0YaHc6",
        "outputId": "3ea6f34c-ce98-413a-acbd-912d4f961217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match found in ID1.txt\n",
            "selenium : {'counter': 1, 'cordinate': [(1, 6)]}\n",
            "web : {'counter': 1, 'cordinate': [(1, 6)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION : 2**\n",
        "pt 2"
      ],
      "metadata": {
        "id": "bQQloxKqc2E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "textfiles =['ID1','ID2','ID3','ID4','ID5'] \n",
        "indexer={}\n",
        "for id,doc in enumerate(textfiles): \n",
        "   filenum = doc+\".txt\" \n",
        "   with open(filenum,'r') as fp: \n",
        "    data = \"\".join(fp.readlines()) \n",
        "    data = data.lower() \n",
        "    # extractwords = re.findall(r\"([a-z0-9-]+)\",data) \n",
        "    # for position,word in enumerate(extractwords): \n",
        "    #   if word[-1]=='s': \n",
        "    #     if word[:-1] in indexer: \n",
        "    #       word = word[:-1] \n",
        "    #     elif word[:-2] in indexer: \n",
        "    #       word = word[:-2] \n",
        "    print(\"Match found in\", filenum)\n",
        "    ext_words1 = re.findall(r\"\\bsoup\\b\", data) \n",
        "    #ext_words2 = re.findall(r\"\\bweb\\b\", data) \n",
        "    for pos,word in enumerate(ext_words1):\n",
        "      if word not in indexer: \n",
        "        indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "      else: \n",
        "          indexer[word]['counter']+=1 \n",
        "          indexer[word]['cordinate'].append((id+1,position)) \n",
        "      # for pos,word in enumerate(ext_words2):\n",
        "      #   if word not in indexer: \n",
        "      #     indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "      #   else: \n",
        "      #     indexer[word]['counter']+=1 \n",
        "      #     indexer[word]['cordinate'].append((id+1,position)) \n",
        "\n",
        "from collections import OrderedDict \n",
        "pos = OrderedDict(sorted(indexer.items())) \n",
        "with open(\"inverted.txt\",'w') as fp: \n",
        "      for key in pos: \n",
        "        print(f\"{key} : {pos[key]}\") \n",
        "        fp.write(f\"{key} : {pos[key]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KScB2NOFcv_w",
        "outputId": "9366d8d8-bd0a-4171-adfc-31df67fc4dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match found in ID1.txt\n",
            "Match found in ID2.txt\n",
            "Match found in ID3.txt\n",
            "Match found in ID4.txt\n",
            "Match found in ID5.txt\n",
            "soup : {'counter': 1, 'cordinate': [(2, 6)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION : 2**\n",
        "pt 3"
      ],
      "metadata": {
        "id": "18Ca7ux7c8x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "textfiles =['ID1','ID2','ID3','ID4','ID5'] \n",
        "indexer={}\n",
        "for id,doc in enumerate(textfiles): \n",
        "   filenum = doc+\".txt\" \n",
        "   with open(filenum,'r') as fp: \n",
        "    data = \"\".join(fp.readlines()) \n",
        "    data = data.lower() \n",
        "    # extractwords = re.findall(r\"([a-z0-9-]+)\",data) \n",
        "    # for position,word in enumerate(extractwords): \n",
        "    #   if word[-1]=='s': \n",
        "    #     if word[:-1] in indexer: \n",
        "    #       word = word[:-1] \n",
        "    #     elif word[:-2] in indexer: \n",
        "    #       word = word[:-2] \n",
        "    print(\"Match found in\", filenum)\n",
        "    ext_words1 = re.compile(r\"\\bpython\\b | \\bjava\\b\", flags = re.I | re.X) \n",
        "    ext_words2 = ext_words1.findall(data)\n",
        "    for pos,word in enumerate(ext_words2):\n",
        "      if word not in indexer: \n",
        "        indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "      else: \n",
        "          indexer[word]['counter']+=1 \n",
        "          indexer[word]['cordinate'].append((id+1,position)) \n",
        "      # for pos,word in enumerate(ext_words2):\n",
        "      #   if word not in indexer: \n",
        "      #     indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "      #   else: \n",
        "      #     indexer[word]['counter']+=1 \n",
        "      #     indexer[word]['cordinate'].append((id+1,position)) \n",
        "\n",
        "from collections import OrderedDict \n",
        "pos = OrderedDict(sorted(indexer.items())) \n",
        "with open(\"inverted.txt\",'w') as fp: \n",
        "      for key in pos: \n",
        "        print(f\"{key} : {pos[key]}\") \n",
        "        fp.write(f\"{key} : {pos[key]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgEGhWt-c-DN",
        "outputId": "01472d29-4815-49b7-d7aa-1b76158ff6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match found in ID1.txt\n",
            "Match found in ID2.txt\n",
            "Match found in ID3.txt\n",
            "Match found in ID4.txt\n",
            "Match found in ID5.txt\n",
            "java : {'counter': 1, 'cordinate': [(4, 6)]}\n",
            "python : {'counter': 1, 'cordinate': [(3, 6)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION : 2**\n",
        "pt 4"
      ],
      "metadata": {
        "id": "gI1-I_L-dAMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "textfiles =['ID1','ID2','ID3','ID4','ID5'] \n",
        "indexer={}\n",
        "for id,doc in enumerate(textfiles): \n",
        "   filenum = doc+\".txt\" \n",
        "   with open(filenum,'r') as fp: \n",
        "    data = \"\".join(fp.readlines()) \n",
        "    data = data.lower() \n",
        "    # extractwords = re.findall(r\"([a-z0-9-]+)\",data) \n",
        "    # for position,word in enumerate(extractwords): \n",
        "    #   if word[-1]=='s': \n",
        "    #     if word[:-1] in indexer: \n",
        "    #       word = word[:-1] \n",
        "    #     elif word[:-2] in indexer: \n",
        "    #       word = word[:-2] \n",
        "    if re.findall(r\"\\bweb\\b\", data) and re.findall(r\"\\bcraw\\b\", data):\n",
        "      print(\"Match found in\", filenum)\n",
        "      ext_words1 = re.findall(r\"\\bweb\\b\", data) \n",
        "      ext_words2 = re.findall(r\"\\bcraw\\b\", data) \n",
        "      for pos,word in enumerate(ext_words1):\n",
        "        if word not in indexer: \n",
        "          indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "        else: \n",
        "          indexer[word]['counter']+=1 \n",
        "          indexer[word]['cordinate'].append((id+1,position)) \n",
        "      for pos,word in enumerate(ext_words2):\n",
        "        if word not in indexer: \n",
        "          indexer[word]={ \"counter\":1, \"cordinate\": [(id+1,position)] } \n",
        "        else: \n",
        "          indexer[word]['counter']+=1 \n",
        "          indexer[word]['cordinate'].append((id+1,position)) \n",
        "    else:\n",
        "          print(\"no match\")\n",
        "from collections import OrderedDict \n",
        "pos = OrderedDict(sorted(indexer.items())) \n",
        "with open(\"inverted.txt\",'w') as fp: \n",
        "  for key in pos: \n",
        "    print(f\"{key} : {pos[key]}\") \n",
        "    fp.write(f\"{key} : {pos[key]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3-jIC4Lc_0_",
        "outputId": "62bf6b4b-07f0-4cff-a44a-eee987f82c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no match\n",
            "no match\n",
            "no match\n",
            "no match\n",
            "no match\n"
          ]
        }
      ]
    }
  ]
}